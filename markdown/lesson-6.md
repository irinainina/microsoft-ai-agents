## Урок 6: Создание надёжных AI-агентов

### Введение

В этом уроке вы узнаете:

* Как создавать и развёртывать безопасных и эффективных AI-агентов.
* Важные соображения по безопасности при разработке AI-агентов.
* Как обеспечивать конфиденциальность данных и пользователей при работе агентов.

### Цели обучения

После прохождения урока вы сможете:

* Выявлять и снижать риски при создании AI-агентов.
* Реализовывать меры безопасности для защиты данных и доступа.
* Создавать агентов, сохраняющих конфиденциальность данных и обеспечивающих качественный пользовательский опыт.

---

### Безопасность

#### Создание структуры системных сообщений (System Message Framework)

Системное сообщение — это основа поведения агента. Оно задаёт правила и инструкции, которых должен придерживаться агент.

##### Шаг 1: Meta System Message

Создаётся шаблон системного сообщения, который LLM будет использовать для генерации системных сообщений конкретных агентов.
Пример:

```
Ты — эксперт по созданию AI-ассистентов. Тебе будет предоставлена информация о компании, роли и обязанностях. Используя её, сгенерируй системное сообщение для ассистента. Будь как можно более описательным и структурированным.
```

##### Шаг 2: Basic Prompt

Пример базового описания агента:

```
Ты — турагент компании Contoso Travel. Задачи: искать и бронировать рейсы, узнавать предпочтения по сидениям и времени, отменять брони, уведомлять об изменениях.
```

##### Шаг 3: Генерация системного сообщения

Подставляем meta-подсказку + basic prompt → получаем итоговое системное сообщение для агента (с ролью, задачами, тоном и поведением).

##### Шаг 4: Итерация

Изменяя basic prompt, можно быстро улучшать поведение агента и создавать новые роли по шаблону.

---

### Понимание угроз

#### Основные типы атак и способы защиты:

* **Task and Instruction Manipulation**

  * *Описание*: злоумышленник изменяет инструкции агента через ввод.
  * *Защита*: фильтрация входных данных, ограничение количества ходов.

* **Доступ к критическим системам**

  * *Описание*: агент может стать каналом доступа к защищённым данным.
  * *Защита*: минимальные привилегии, безопасная передача, аутентификация.

* **Перегрузка ресурсов**

  * *Описание*: злоумышленник создаёт чрезмерную нагрузку через агента.
  * *Защита*: лимиты на обращения, ограничения сессий.

* **Отравление базы знаний (Knowledge Base Poisoning)**

  * *Описание*: подмена данных, на которых основываются решения агента.
  * *Защита*: проверка источников, контроль доступа к данным.

* **Каскадные ошибки**

  * *Описание*: ошибка в одном сервисе вызывает сбои в других.
  * *Защита*: изоляция (например, в Docker), fallback-логика, повторные попытки.

---

### Вовлечение человека (Human-in-the-loop)

Модель, в которой пользователь подтверждает действия агента в процессе выполнения.

Пример реализации в AutoGen:

```python
model_client = OpenAIChatCompletionClient(model="gpt-4o-mini")
assistant = AssistantAgent("assistant", model_client=model_client)
user_proxy = UserProxyAgent("user_proxy", input_func=input)

termination = TextMentionTermination("APPROVE")

team = RoundRobinGroupChat([assistant, user_proxy], termination_condition=termination)
stream = team.run_stream(task="Напиши 4-строчное стихотворение об океане.")
await Console(stream)
```

---

### Заключение

Создание надёжных AI-агентов требует:

* чёткого проектирования (структурированные system messages),
* знаний об угрозах и способов защиты,
* постоянной итерации и улучшений,
* включения человека в процесс (Human-in-the-loop),
* соблюдения конфиденциальности и этических принципов.

Безопасность и доверие — ключевые аспекты в построении AI-систем будущего.
